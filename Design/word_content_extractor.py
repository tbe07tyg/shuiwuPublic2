#!/usr/bin/env python3
"""
Wordæ–‡æ¡£å†…å®¹æå–å™¨
å°†Wordæ–‡æ¡£è½¬æ¢ä¸ºå¯è¢«Cursor @å¼•ç”¨çš„æ–‡æœ¬æ–‡ä»¶
"""

import os
import json
from docx import Document
from pathlib import Path

def extract_word_to_text(word_file_path, output_dir="word_content"):
    """å°†Wordæ–‡æ¡£å†…å®¹æå–ä¸ºæ–‡æœ¬æ–‡ä»¶"""
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # è¯»å–Wordæ–‡æ¡£
        doc = Document(word_file_path)
        
        # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
        file_name = Path(word_file_path).stem
        
        # åˆ›å»ºæ–‡æœ¬æ–‡ä»¶è·¯å¾„
        text_file_path = os.path.join(output_dir, f"{file_name}.md")
        
        # æå–å†…å®¹å¹¶å†™å…¥Markdownæ–‡ä»¶
        with open(text_file_path, 'w', encoding='utf-8') as f:
            f.write(f"# Wordæ–‡æ¡£å†…å®¹: {file_name}\n\n")
            f.write(f"**åŸæ–‡æ¡£è·¯å¾„**: {word_file_path}\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {Path(word_file_path).stat().st_mtime}\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            f.write("## ğŸ“Š æ–‡æ¡£ä¿¡æ¯\n\n")
            f.write(f"- æ®µè½æ•°é‡: {len(doc.paragraphs)}\n")
            f.write(f"- è¡¨æ ¼æ•°é‡: {len(doc.tables)}\n")
            f.write(f"- æ€»å­—ç¬¦æ•°: {sum(len(p.text) for p in doc.paragraphs)}\n\n")
            
            # æå–æ–‡æ¡£å†…å®¹
            f.write("## ğŸ“– æ–‡æ¡£å†…å®¹\n\n")
            
            current_heading_level = 0
            for para in doc.paragraphs:
                if para.text.strip():
                    style_name = para.style.name
                    text = para.text.strip()
                    
                    # å¤„ç†æ ‡é¢˜
                    if style_name == 'Title':
                        f.write(f"# {text}\n\n")
                    elif 'Heading 1' in style_name:
                        f.write(f"## {text}\n\n")
                    elif 'Heading 2' in style_name:
                        f.write(f"### {text}\n\n")
                    elif 'Heading 3' in style_name:
                        f.write(f"#### {text}\n\n")
                    elif 'List Bullet' in style_name:
                        f.write(f"- {text}\n")
                    elif 'List Number' in style_name:
                        f.write(f"1. {text}\n")
                    else:
                        f.write(f"{text}\n\n")
            
            # æå–è¡¨æ ¼æ•°æ®
            if doc.tables:
                f.write("## ğŸ“‹ è¡¨æ ¼æ•°æ®\n\n")
                for i, table in enumerate(doc.tables, 1):
                    f.write(f"### è¡¨æ ¼ {i}\n\n")
                    
                    # æå–è¡¨æ ¼å†…å®¹ä¸ºMarkdownè¡¨æ ¼
                    if table.rows:
                        # è¡¨å¤´
                        header_row = table.rows[0]
                        headers = [cell.text.strip() for cell in header_row.cells]
                        f.write("| " + " | ".join(headers) + " |\n")
                        f.write("| " + " | ".join(["---"] * len(headers)) + " |\n")
                        
                        # æ•°æ®è¡Œ
                        for row in table.rows[1:]:
                            row_data = [cell.text.strip() for cell in row.cells]
                            f.write("| " + " | ".join(row_data) + " |\n")
                        f.write("\n")
        
        return text_file_path
        
    except Exception as e:
        print(f"æå–å¤±è´¥: {str(e)}")
        return None

def batch_extract_words():
    """æ‰¹é‡æå–å·¥ä½œåŒºä¸­çš„æ‰€æœ‰Wordæ–‡æ¡£"""
    word_files = []
    
    # æŸ¥æ‰¾æ‰€æœ‰Wordæ–‡æ¡£
    for root, dirs, files in os.walk("."):
        for file in files:
            if file.endswith('.docx') and not file.startswith('~'):
                full_path = os.path.join(root, file)
                word_files.append(full_path)
    
    print(f"ğŸ” æ‰¾åˆ° {len(word_files)} ä¸ªWordæ–‡æ¡£")
    
    extracted_files = []
    for word_file in word_files:
        print(f"ğŸ“„ æ­£åœ¨å¤„ç†: {word_file}")
        text_file = extract_word_to_text(word_file)
        if text_file:
            extracted_files.append(text_file)
            print(f"âœ… å·²è½¬æ¢: {text_file}")
    
    print(f"\nğŸ‰ è½¬æ¢å®Œæˆï¼ç”Ÿæˆäº† {len(extracted_files)} ä¸ªå¯@å¼•ç”¨çš„æ–‡ä»¶:")
    for file in extracted_files:
        print(f"   ğŸ“ {file}")
    
    print("\nğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥åœ¨Cursorä¸­ä½¿ç”¨ @word_content/æ–‡ä»¶å.md æ¥å¼•ç”¨Wordæ–‡æ¡£å†…å®¹äº†ï¼")
    
    return extracted_files

if __name__ == "__main__":
    batch_extract_words() 